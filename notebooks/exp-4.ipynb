{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28834\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "CSV_ROWS = [\n",
    "    \"Photo_Name\",\n",
    "    \"Id\",\n",
    "    \"Sex\",\n",
    "    \"dob\",\n",
    "    \"dob_estimated\",\n",
    "    \"error_dob\",\n",
    "    \"FaceView\",\n",
    "    \"FaceQual\",\n",
    "    \"Shootdate\"\n",
    "]\n",
    "\n",
    "def csvdate_to_date(shoot_date):\n",
    "    year, month, day = shoot_date.split(\"-\")\n",
    "    return datetime.date(int(year), int(month), int(day))    \n",
    "\n",
    "def compute_age(row):\n",
    "    photo_date = csvdate_to_date(row[\"Shootdate\"])\n",
    "    dob_date = csvdate_to_date(row[\"dob\"])\n",
    "    age = photo_date - dob_date\n",
    "    return age.days\n",
    "\n",
    "def add(row):\n",
    "   return row[0]+row[1]+row[2]\n",
    "\n",
    "data = pd.read_csv(\"MFD_metadatas.csv\", dtype={'Shootdate': str})\n",
    "data['Shootdate'].replace('nan', np.nan, inplace=True)\n",
    "data = data.dropna()\n",
    "data['age'] = data.apply(compute_age, axis=1)\n",
    "\n",
    "def filter_by_age(data, age_in_days):\n",
    "    return data[data['age'] <= age_in_days]\n",
    "\n",
    "def filter_by_certainty(data):\n",
    "    return data[data['dob_estimated'] == False]\n",
    "\n",
    "def filter_dob_errors(data):\n",
    "    return data[data[\"age\"] >= 0]\n",
    "\n",
    "# data[\"age\"].hist(bins=25)\n",
    "\n",
    "# data = filter_by_certainty(data)\n",
    "data = filter_dob_errors(data)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# data[\"age\"].hist(bins=25)\n",
    "print(len(data))\n",
    "\n",
    "max_age = 25\n",
    "max_days = 365 * max_age\n",
    "\n",
    "one_year_data = filter_by_age(data, age_in_days=max_days)\n",
    "one_year_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "hist = one_year_data[\"age\"].hist(bins=25)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_qty(df, bins):\n",
    "    value_range = pd.cut(df['age'], bins)\n",
    "\n",
    "    print(value_range)\n",
    "    # Count the occurrences of each value range\n",
    "    range_counts = value_range.value_counts()\n",
    "\n",
    "    # Find the minimum count among the value ranges\n",
    "    min_count = range_counts.min()\n",
    "    print(range_counts)\n",
    "\n",
    "    # Filter the DataFrame to have the same number of occurrences for each value range\n",
    "    filtered_df = df.groupby(value_range).apply(lambda x: x.sample(200, replace=True))\n",
    "\n",
    "    # Reset the index of the filtered DataFrame\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "    return filtered_df\n",
    "\n",
    "#one_year_data = filter_by_qty(one_year_data, bins=50)\n",
    "#one_year_data.reset_index(inplace=True, drop=True)\n",
    "#one_year_data[\"age\"].hist(bins=25)\n",
    "#len(one_year_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28834/28834 [02:34<00:00, 186.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Tesla T4\n",
      "Memory Usage:\n",
      "Allocated: 1.2 GB\n",
      "Cached:    1.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:19<00:00,  1.22s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from inf to 0.0574\n",
      "Epoch [1/500] - Train Loss: 5271.17126 - Train Dual loss: 0.92870 - Val L1: 0.05737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:05<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from 0.0574 to 0.0467\n",
      "Epoch [2/500] - Train Loss: 897.79204 - Train Dual loss: 0.79702 - Val L1: 0.04668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:06<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:14<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0467\n",
      "Epoch [3/500] - Train Loss: 660.68921 - Train Dual loss: 0.71530 - Val L1: 0.05909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:06<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from 0.0467 to 0.0375\n",
      "Epoch [4/500] - Train Loss: 574.29105 - Train Dual loss: 0.64912 - Val L1: 0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:03<00:00,  1.17s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0375\n",
      "Epoch [5/500] - Train Loss: 499.13567 - Train Dual loss: 0.59650 - Val L1: 0.03757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:05<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0375\n",
      "Epoch [6/500] - Train Loss: 398.63484 - Train Dual loss: 0.55165 - Val L1: 0.03795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:04<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from 0.0375 to 0.0359\n",
      "Epoch [7/500] - Train Loss: 381.02773 - Train Dual loss: 0.51078 - Val L1: 0.03590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:03<00:00,  1.17s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from 0.0359 to 0.0311\n",
      "Epoch [8/500] - Train Loss: 301.49039 - Train Dual loss: 0.47384 - Val L1: 0.03114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:03<00:00,  1.17s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0311\n",
      "Epoch [9/500] - Train Loss: 299.11232 - Train Dual loss: 0.44382 - Val L1: 0.03228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:04<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0311\n",
      "Epoch [10/500] - Train Loss: 268.57775 - Train Dual loss: 0.41697 - Val L1: 0.03406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:04<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0311\n",
      "Epoch [11/500] - Train Loss: 262.86569 - Train Dual loss: 0.39049 - Val L1: 0.03408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:04<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0311\n",
      "Epoch [12/500] - Train Loss: 227.07734 - Train Dual loss: 0.36537 - Val L1: 0.03514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:04<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0311\n",
      "Epoch [13/500] - Train Loss: 206.76359 - Train Dual loss: 0.34627 - Val L1: 0.03354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:05<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from 0.0311 to 0.0304\n",
      "Epoch [14/500] - Train Loss: 206.94924 - Train Dual loss: 0.32499 - Val L1: 0.03041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:04<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from 0.0304 to 0.0277\n",
      "Epoch [15/500] - Train Loss: 164.17012 - Train Dual loss: 0.31304 - Val L1: 0.02771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:05<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0277\n",
      "Epoch [16/500] - Train Loss: 166.51475 - Train Dual loss: 0.29346 - Val L1: 0.02797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:03<00:00,  1.17s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from 0.0277 to 0.0263\n",
      "Epoch [17/500] - Train Loss: 139.24956 - Train Dual loss: 0.28182 - Val L1: 0.02627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:06<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0263\n",
      "Epoch [18/500] - Train Loss: 141.50537 - Train Dual loss: 0.26968 - Val L1: 0.02938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:06<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0263\n",
      "Epoch [19/500] - Train Loss: 135.05692 - Train Dual loss: 0.25623 - Val L1: 0.03207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:05<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from 0.0263 to 0.0253\n",
      "Epoch [20/500] - Train Loss: 127.64322 - Train Dual loss: 0.24629 - Val L1: 0.02528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:04<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0253\n",
      "Epoch [21/500] - Train Loss: 113.91151 - Train Dual loss: 0.23374 - Val L1: 0.02633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:04<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from 0.0253 to 0.0252\n",
      "Epoch [22/500] - Train Loss: 119.78758 - Train Dual loss: 0.22861 - Val L1: 0.02518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:04<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0252\n",
      "Epoch [23/500] - Train Loss: 100.63225 - Train Dual loss: 0.21804 - Val L1: 0.02565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:05<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improved from 0.0252\n",
      "Epoch [24/500] - Train Loss: 92.96303 - Train Dual loss: 0.20882 - Val L1: 0.02716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:05<00:00,  1.18s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from 0.0252 to 0.0240\n",
      "Epoch [25/500] - Train Loss: 107.92178 - Train Dual loss: 0.20010 - Val L1: 0.02396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [07:03<00:00,  1.17s/it]\n",
      "100%|██████████| 91/91 [00:13<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss improved from 0.0240 to 0.0226\n",
      "Epoch [26/500] - Train Loss: 89.61135 - Train Dual loss: 0.19391 - Val L1: 0.02264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 111/361 [02:10<04:55,  1.18s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.models import resnet18\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Define your custom dataset\n",
    "class MandrillImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, dataframe, img_size=(224, 224), device=\"cuda\", in_mem=True):\n",
    "        self.df = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.img_size = img_size\n",
    "        self.in_mem = in_mem\n",
    "        if self.in_mem:\n",
    "            self.images = []\n",
    "            for i in tqdm(range(len(self.df))):\n",
    "                row = self.df.iloc[[i]]\n",
    "                self.images.append(self.load_photo(row))\n",
    "\n",
    "    def load_photo(self, row):\n",
    "        image_path = self.photo_path(row)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image.shape[0:2] != self.img_size:\n",
    "            image = cv2.resize(image, self.img_size, interpolation = cv2.INTER_AREA)\n",
    "        image = np.moveaxis(image, -1, 0) # Channel first format\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        return image\n",
    "            \n",
    "    def photo_path(self, row):\n",
    "        return os.path.join(self.root_dir, f\"{row['Id'].values[0]}\", f\"{row['Photo_Name'].values[0]}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def _getpair(self, idx):\n",
    "        row = self.df.iloc[[idx]]\n",
    "\n",
    "        target = float(row[\"age\"].values[0])\n",
    "        target = target / max_days\n",
    "\n",
    "        if self.in_mem:\n",
    "            image = self.images[idx]\n",
    "        else:\n",
    "            image = self.load_photo(row)\n",
    "        return torch.tensor(image).to(device), torch.tensor(target).to(device)\n",
    "    \n",
    "    def set_images(self, images):\n",
    "        self.images = images\n",
    "        self.in_mem = True\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self._getpair(idx)\n",
    "\n",
    "class MandrillDualImageDataset(MandrillImageDataset):\n",
    "    def __init__(self, root_dir, dataframe, img_size=(224, 224), device=\"cuda\", images=None, in_mem=False):\n",
    "        super(MandrillDualImageDataset, self).__init__(root_dir, dataframe, img_size, device, in_mem)\n",
    "        if images is not None:\n",
    "            self.images = images\n",
    "            self.in_mem = True\n",
    "                    \n",
    "    def get_same_mandrill_idx(self, mandrill_id):\n",
    "        ids = self.df[self.df.Id == mandrill_id].index\n",
    "        return ids\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Randomize\n",
    "        idx = random.randint(0, len(self)-1)\n",
    "        #row = self.df.iloc[[idx]]\n",
    "        #mandrill_id = row[\"Id\"].values[0]\n",
    "        #ids = self.get_same_mandrill_idx(mandrill_id)\n",
    "        #second_idx = random.choice(ids)\n",
    "        \n",
    "        second_idx = random.randint(0, len(self)-1)\n",
    "        x1, y1 = self._getpair(idx)\n",
    "        x2, y2 = self._getpair(second_idx)\n",
    "\n",
    "        # y1 = y1.cpu().numpy()\n",
    "        # y2 = y2.cpu().numpy()\n",
    "        sign = torch.sign(y1 - y2)\n",
    "        y = torch.zeros([3], device=device)\n",
    "        y[int(sign) + 1] = 1\n",
    "        return [x1, x2], y\n",
    "\n",
    "class MandrillTripleImageDataset(MandrillImageDataset):\n",
    "    def __init__(self, root_dir, dataframe, img_size=(224, 224), device=\"cuda\", images=None, in_mem=False):\n",
    "        super(MandrillTripleImageDataset, self).__init__(root_dir, dataframe, img_size, device, in_mem)\n",
    "        if images is not None:\n",
    "            self.images = images\n",
    "            self.in_mem = True\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get three random idx\n",
    "        second_idx = random.randint(0, len(self)-1)\n",
    "        third_idx = random.randint(0, len(self)-1)\n",
    "        x1, y1 = self._getpair(idx)\n",
    "        x2, y2 = self._getpair(idx2)\n",
    "        x3, y3 = self._getpair(idx3)\n",
    "        \n",
    "        y2y1 = abs(y1 - y2)\n",
    "        y3y1 = abs(y1 - y3)\n",
    "        \n",
    "        if y2y1 > y3y1:\n",
    "            triplet = ((x1, x3, x2), (y1, y3, y2))\n",
    "        else:\n",
    "            triplet = ((x1, x2, x3), (y1, y2, y3))\n",
    "        x, y = triplet\n",
    "        return x, y\n",
    "    \n",
    "# Define your model\n",
    "from collections import OrderedDict\n",
    "def build_layers(n, method, prev_features, current_features, down=True):\n",
    "    layers = OrderedDict()\n",
    "    for i in range(n):\n",
    "        layers[str(i)] = method(prev_features, current_features)\n",
    "        prev_features = current_features\n",
    "        if down:\n",
    "            current_features = current_features // 2\n",
    "        else:\n",
    "            current_features = current_features * 2\n",
    "    return layers, prev_features\n",
    "\n",
    "    \n",
    "class BackboneRegressionModel(nn.Module):\n",
    "    def __init__(self, im_size=224, n_channels=3, conv_start=64, n_convs=5):\n",
    "        super(BackboneRegressionModel, self).__init__()\n",
    "        previous_feature_size = n_channels\n",
    "        current_feature_size = conv_start\n",
    "        convs_layers, last_feature_size = build_layers(\n",
    "            n_convs, self.conv_block, previous_feature_size, current_feature_size, down=False\n",
    "        )\n",
    "        self.conv_blocks = nn.Sequential(convs_layers)\n",
    "        \n",
    "        last_scale = (2 ** (n_convs))\n",
    "        last_size = im_size // last_scale\n",
    "        self.last_layer_size = last_feature_size * last_size * last_size\n",
    "\n",
    "    def conv_block(self, in_features, out_features):\n",
    "        conv = nn.Conv2d(in_features, out_features, 3, padding=\"same\")\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        bn = nn.BatchNorm2d(out_features)\n",
    "        pool = nn.MaxPool2d((2,2))\n",
    "        return nn.Sequential(conv, relu, bn, pool)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv_blocks(x)\n",
    "\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, cnn_backbone, lin_start=2048, n_lin=6):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.cnn_backbone = cnn_backbone\n",
    "\n",
    "        ############ Dense layers ########\n",
    "        previous_feature_size = self.cnn_backbone.last_layer_size\n",
    "        current_feature_size = lin_start\n",
    "        lin_layers, last_feature_size = build_layers(\n",
    "            n_lin, self.block, previous_feature_size, current_feature_size\n",
    "        )\n",
    "        self.blocks = nn.Sequential(lin_layers)\n",
    "        self.age = nn.Linear(last_feature_size, 1)\n",
    "\n",
    "    def block(self, in_features, out_features):\n",
    "        lin = nn.Linear(in_features, out_features)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        return nn.Sequential(lin, relu)\n",
    "\n",
    "    def __del__(self):\n",
    "        del self.conv_blocks\n",
    "        del self.blocks\n",
    "        del self.x_coords\n",
    "        del self.y_coords\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.cnn_backbone(x)\n",
    "        z = torch.reshape(z, (z.shape[0], z.shape[1] * z.shape[2] * z.shape[3]))\n",
    "        z = self.blocks(z)\n",
    "        z = self.age(z)\n",
    "        z = torch.reshape(z, (z.shape[0],))\n",
    "        return z\n",
    "\n",
    "class DualRegressionModel(nn.Module):\n",
    "    def __init__(self, cnn_backbone, lin_start=2048, n_lin=6):\n",
    "        super(DualRegressionModel, self).__init__()\n",
    "        self.cnn_backbone = cnn_backbone\n",
    "        \n",
    "        previous_feature_size = 2* self.cnn_backbone.last_layer_size\n",
    "        current_feature_size = lin_start\n",
    "        lin_layers, last_feature_size = build_layers(\n",
    "            n_lin, self.block, previous_feature_size, current_feature_size\n",
    "        )\n",
    "        self.blocks = nn.Sequential(lin_layers)\n",
    "        self.age_gap = nn.Linear(last_feature_size, 3)\n",
    "        # self.activation = nn.Softmax()\n",
    "    \n",
    "    def block(self, in_features, out_features):\n",
    "        lin = nn.Linear(in_features, out_features)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        return nn.Sequential(lin, relu)\n",
    "    \n",
    "    def get_z(self, x):\n",
    "        z = self.cnn_backbone(x)\n",
    "        z = torch.reshape(z, (z.shape[0], z.shape[1] * z.shape[2] * z.shape[3]))\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x\n",
    "        z1 = self.get_z(x1)\n",
    "        z2 = self.get_z(x2)\n",
    "        z = torch.cat([z1, z2], axis=-1)\n",
    "        z = self.blocks(z)\n",
    "        z = self.age_gap(z)\n",
    "        # z = torch.reshape(z, (z.shape[0],))\n",
    "        # z = self.activation(z)\n",
    "        return z\n",
    "\n",
    "class TripletRegressionModel(nn.Module):\n",
    "    def __init__(self, cnn_backbone, lin_start=2048, n_lin=6):\n",
    "        super(TripletRegressionModel, self).__init__()\n",
    "        self.cnn_backbone = cnn_backbone\n",
    "        previous_feature_size = 3* self.cnn_backbone.last_layer_size\n",
    "        current_feature_size = lin_start\n",
    "        lin_layers, last_feature_size = build_layers(\n",
    "            n_lin, self.block, previous_feature_size, current_feature_size\n",
    "        )\n",
    "        self.blocks = nn.Sequential(lin_layers)\n",
    "        self.age_gap = nn.Linear(last_feature_size, 3)\n",
    "    \n",
    "learning_rate = 0.001\n",
    "dual_learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 500\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = MandrillImageDataset(root_dir='Images', dataframe=one_year_data, in_mem=True)\n",
    "dual_dataset = MandrillDualImageDataset(root_dir='Images', dataframe=one_year_data, in_mem=False)\n",
    "dual_dataset.set_images(dataset.images)\n",
    "triplet_dataset = MandrilTripleImageDataset(root_dir='Images', dataframe=one_year_data, in_mem=False)\n",
    "triplet_dataset.set_images(dataset.images)\n",
    "\n",
    "\n",
    "def split_dataset(dataset, train_ratio, batch_size):\n",
    "    # Split the dataset into training and validation subsets\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, train_dataset, val_dataset\n",
    "\n",
    "train_loader, val_loader, train_dataset, val_dataset = split_dataset(dataset, train_ratio, batch_size)\n",
    "dual_train_loader, dual_val_loader, _, _ = split_dataset(dual_dataset, train_ratio, batch_size)\n",
    "triplet_train_loader, triplet_val_loader, _, _ = split_dataset(triplet_dataset, train_ratio, batch_size)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "# Model\n",
    "backbone = BackboneRegressionModel()\n",
    "backbone = backbone.to(device)\n",
    "model = RegressionModel(backbone)\n",
    "dual_model = DualRegressionModel(backbone)\n",
    "triplet_model = TripletRegressionModel(backbone)\n",
    "\n",
    "# Loss function\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WeightedMSELoss, self).__init__()\n",
    "        self.epsilon = 1e-6\n",
    "\n",
    "    def forward(self, prediction, true_value):\n",
    "        log_pred = torch.log(abs(prediction) * self.epsilon) * max_days\n",
    "        log_true = torch.log(abs(true_value) + self.epsilon) * max_days\n",
    "        log_diff = log_true - log_pred # Compute logarithmic difference\n",
    "        weighted_mse = torch.mean(abs(log_diff) * torch.pow(prediction - true_value, 2))  # Weighted MSE\n",
    "        return weighted_mse\n",
    "\n",
    "criterion = WeightedMSELoss()\n",
    "dual_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.L1Loss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "dual_optimizer = optim.Adam(model.parameters(), lr=dual_learning_rate)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "dual_model = dual_model.to(device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    \n",
    "    \n",
    "def train_step(loader, index, optimizer, model, criterion):\n",
    "    images, labels = next(iter(loader))\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    size = 0\n",
    "    if isinstance(images, list):\n",
    "        size = images[0].size(0)\n",
    "    else:\n",
    "        size = images.size(0)\n",
    "\n",
    "    return loss.item() * size\n",
    "    \n",
    "def save(backbone, model, dual_model, prefix):\n",
    "    torch.save(backbone.state_dict(), f\"models/{prefix}_exp4_backbone.h5\")\n",
    "    torch.save(model.state_dict(), f\"models/{prefix}_exp4_model.h5\")\n",
    "    torch.save(dual_model.state_dict(), f\"models/{prefix}exp4_dual_model.h5\")\n",
    "    \n",
    "def load(backbone, model, dual_model, prefix):\n",
    "    backbone.load_state_dict(torch.load(f\"models/{prefix}_exp4_backbone.h5\"))\n",
    "    model.load_state_dict(torch.load(f\"models/{prefix}_exp4_model.h5\"))\n",
    "    dual_model.load_state_dict(torch.load(f\"models/{prefix}exp4_dual_model.h5\"))\n",
    "    return backbone, model, dual_model\n",
    "\n",
    "#######\n",
    "train = True\n",
    "#######\n",
    "    \n",
    "if train:\n",
    "\n",
    "    # Training loop\n",
    "    best_val = np.inf\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to train mode\n",
    "        train_loss = 0.0\n",
    "        dual_train_loss = 0.0\n",
    "        steps = len(train_loader)\n",
    "\n",
    "        for i in tqdm(range(steps)):\n",
    "            train_loss += train_step(train_loader, i, optimizer, model, criterion)\n",
    "            dual_train_loss += train_step(dual_train_loader, i, dual_optimizer, dual_model, dual_criterion)\n",
    "\n",
    "        train_loss /= len(train_dataset)\n",
    "        dual_train_loss /= len(train_dataset)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader):\n",
    "                outputs = model(images)\n",
    "                loss = val_criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "        val_loss /= len(val_dataset)\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            print(f\"Val loss improved from {best_val:.4f} to {val_loss:.4f}\")\n",
    "            best_val = val_loss\n",
    "            save(backbone, model, dual_model, \"best\")\n",
    "        else:\n",
    "            print(f\"Val loss did not improved from {best_val:.4f}\")\n",
    "\n",
    "        # Print training and validation metrics\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "              f\"Train Loss: {train_loss:.5f} - \"\n",
    "              f\"Train Dual loss: {dual_train_loss:.5f} - \"\n",
    "              f\"Val L1: {val_loss:.5f}\")\n",
    "\n",
    "    torch.save(backbone.state_dict(), \"models/exp4_backbone.h5\")\n",
    "    torch.save(model.state_dict(), \"models/exp4_model.h5\")\n",
    "    torch.save(dual_model.state_dict(), \"models/exp4_dual_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "backbone, model, dual_model = load(backbone, model, dual_model, \"best\")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "max_display = 10\n",
    "\n",
    "age_errors = []\n",
    "age_truth = []\n",
    "age_predicted = []\n",
    "\n",
    "# Perform inference on validation images\n",
    "for i, (images, targets) in enumerate(val_loader):\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    \n",
    "    # Convert the outputs to numpy arrays\n",
    "    predicted_values = outputs.squeeze().detach().cpu().numpy() * max_days\n",
    "    actual_values = targets.squeeze().cpu().numpy() * max_days\n",
    "    \n",
    "    age_errors.append(predicted_values - actual_values)\n",
    "    age_truth.append(actual_values)\n",
    "    age_predicted.append(predicted_values)\n",
    "    \n",
    "    if i >= max_display:\n",
    "        continue\n",
    "    \n",
    "    # Visualize the images and predictions\n",
    "    plt.imshow(images.squeeze().cpu().permute(1, 2, 0))\n",
    "    plt.title(f\"Predicted: {predicted_values}, Actual: {actual_values}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Display the results\n",
    "    print(\"Predicted Values:\", predicted_values, \" (years : \", predicted_values / 365, \" )\")\n",
    "    print(\"Actual Values:\", actual_values, \" (years : \", actual_values / 365, \" ) \")\n",
    "    print(\"Prediction Error: \", (predicted_values - actual_values) / 365)\n",
    "    print()  # Add an empty line for separation\n",
    "    \n",
    "    \n",
    "age_errors = np.array(age_errors)\n",
    "print(\"Age error (in days): \", np.mean(age_errors), \" std: \", np.std(age_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram with x being the real age and y being the error on this age\n",
    "# Plotting the histogram\n",
    "\n",
    "def group_by(x, n_bins):\n",
    "    step = np.max(x) / n_bins\n",
    "    x = np.array(x)\n",
    "    for i in range(n_bins+1):\n",
    "        nx = i*step\n",
    "        px = max(0, (i-1)*step)\n",
    "        x[np.logical_and(x <= nx, x > px)] = nx\n",
    "    x[np.logical_and(x <= np.max(x), x > (n_bins*step))] = np.max(x)\n",
    "    return x.tolist()\n",
    "\n",
    "def bin_errors(x, y):\n",
    "    bins = np.unique(x)\n",
    "    y_mean = []\n",
    "    y_err = []\n",
    "    y = np.array(y)\n",
    "    for b in bins:\n",
    "        y_bin = y[x == b]\n",
    "        y_mean.append(np.mean(y_bin))\n",
    "        y_err.append(np.std(y_bin))\n",
    "    return np.array(y_mean), np.array(y_err)\n",
    "\n",
    "n_bins = 25*2\n",
    "\n",
    "x = age_truth\n",
    "y = age_errors\n",
    "\n",
    "sorted_lists = sorted(zip(x, y))\n",
    "sorted_x, sorted_y = zip(*sorted_lists)\n",
    "\n",
    "def display_error_curve(x, y, n_bins):\n",
    "    x = group_by(x, n_bins)\n",
    "    y, y_err = bin_errors(x, y)\n",
    "    x = np.unique(x)\n",
    "\n",
    "    plt.plot(x, y, 'k-', label='Prediction error')\n",
    "    plt.fill_between(x, y-y_err, y+y_err)\n",
    "    \n",
    "    z = np.poly1d(np.polyfit(x, y, 2))\n",
    "    plt.plot(x, z(x), color='red')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "display_error_curve(sorted_x, sorted_y, n_bins)\n",
    "display_error_curve(sorted_x, abs(np.array(sorted_y)), n_bins)\n",
    "\n",
    "# Distribution of image according to the age\n",
    "hist = one_year_data[\"age\"].hist(bins=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtf",
   "language": "python",
   "name": "vtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
